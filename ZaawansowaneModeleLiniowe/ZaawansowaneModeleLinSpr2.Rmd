---
title: "Zaawansowane Modele Liniowe Sprawozdanie 2"
knit: (function(input_file, encoding) {
  out_dir <- '../docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'Modele2.html'))})
author: "Błażej Wiórek"
date: "3/28/2020"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(gridExtra)
library(MASS)

knitr::opts_chunk$set(echo = TRUE)

set.seed(47)
```

## Zadanie 1

### Podpunkt a)

```{r data}
data <- structure(list(numeracy = c(6.6, 7.1, 7.3, 7.5, 7.9, 7.9, 8,
                                 8.2, 8.3, 8.3, 8.4, 8.4, 8.6, 8.7, 8.8, 8.8, 9.1, 9.1, 9.1, 9.3,
                                 9.5, 9.8, 10.1, 10.5, 10.6, 10.6, 10.6, 10.7, 10.8, 11, 11.1,
                                 11.2, 11.3, 12, 12.3, 12.4, 12.8, 12.8, 12.9, 13.4, 13.5, 13.6,
                                 13.8, 14.2, 14.3, 14.5, 14.6, 15, 15.1, 15.7), 
                    anxiety = c(13.8, 14.6, 17.4, 14.9, 13.4, 13.5, 13.8, 16.6, 13.5, 15.7, 13.6, 14,
                                16.1, 10.5, 16.9, 17.4, 13.9, 15.8, 16.4, 14.7, 15, 13.3, 10.9,
                                12.4, 12.9, 16.6, 16.9, 15.4, 13.1, 17.3, 13.1, 14, 17.7, 10.6,
                                14.7, 10.1, 11.6, 14.2, 12.1, 13.9, 11.4, 15.1, 13, 11.3, 11.4,
                                10.4, 14.4, 11, 14, 13.4), 
                    success = c(0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
                                1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
                                1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L)), 
                 .Names = c("numeracy", "anxiety", "success"), row.names = c(NA, -50L), class = "data.frame")
data_df <- as.data.frame(data)
```

Na podstawie twierdzenia podanego na wykładzie, estymator parametrów regresji logistycznej jest asymptotycznie normalny tzn:
$$
\hat{\beta} \sim N(\beta, (X^T S(\beta) X)^{-1})
$$

Twierdzenie umożliwa obliczenie estymatora macierzy kowariancji wektora estymatorów w modelu regresji logistycznej. Wystarczy wstawić we wzorze na macierz kowariancji $\hat{\beta}$ zamiast $\beta$. Otrzymuje wtedy: $(X^T S(\hat{\beta}) X)^{-1}$ 
```{r cov_mtrx}
model1 <- glm(success ~ numeracy + anxiety, data=data_df, family=binomial)
model1_summary <- summary(model1)
p <- model1$fitted.values
glm_cov_estimate <- vcov(model1)

X <- cbind(intercept=1, data_df)
X <- subset(X, select = -c(success))
X <- as.matrix(X)
W <- as.matrix(diag(p*(1-p)))

manual_cov_estimate <- solve(t(X) %*% W %*% X)
```

```{r glm_cov_estimate}
coefs_std  <- model1_summary$coefficients[, 2]
cov_estimate_std <- sqrt(diag(manual_cov_estimate))
std_comparison_df <- data.frame("GLM std" = coefs_std, "Cov std" = cov_estimate_std)
std_comparison_df
```

### Podpunkt b)

Chce przetestować hipotezę, że obie zmienne objaśniające nie mają wpływu na zmienną objaśnianą. Formalnie test mogę zapisać jako: $H0: \beta_{numeracy} = 0 \land \beta_{anxiety} = 0$ przy alternatywie $HA: \beta_{numeracy} \neq 0 \lor \beta_{anxiety} \neq 0$. Statystyka testowa ma postać: $\chi^2 = D(M1) - D(M2) \sim \chi^2_1$. $D(M1)$ oznacza deviance modelu w którym zachodzi $H0$, natomiast $D(M2)$ oznacza deviance modelu w którym zachodzi $HA$.

```{r chi_sq_test}
chi_sq_stat <- model1$null.deviance - model1$deviance
p_value <- pchisq(chi_sq_stat, df=1, lower.tail = FALSE)
print(paste("p-value for predictors importance: ", p_value))
```

Tak niska p-wartość daje podstawy do odrzucenia hipotezy zerowej na rzecz hipotezy alternatywnej. 

### Podpunkt c)

Nadmierna dyspersja to sytuacja w której wariancja założonego rozkładu jest mniejsza niż wariancja obserwowana w danych. W przypadku regresji logistycznej mogę mówić o nadmiernej dyspersji gdy obserwowana wariancja $y_i$ jest większa niż $Var[\hat{p}] = \frac{p(1-p)}{n}$. Istnieją dwie podstawowe przyczyny występowania tego zjawiska:

1. Prawdopodobieństwo, że Y=1 zmienia się w kolejnych próbach
2. Prawdopodobieństwa w poszczególnych próbach nie spełniają warunku niezależności. 

Test na podstawie którego można wnioskować o nadmiernej dyspersji to test dopasowania modelu obliczany na podstawie statystyki Pearsona, residual deviance i liczby stopni swobody residual deviance.
```{r overdispersion_test}
overdispersion_stat <- sum(residuals(model1, type = "deviance")^2)
overdispersion_pval <- pchisq(overdispersion_stat, model1$df.residual, lower = F)
print(paste("P-value connected with test for overdispersion: ", overdispersion_pval))
```

Wysoka p-wartość wskazuje, że brak podstaw do stwierdzenia występowania zjawiska najdmiernej dyspersji. 

### Podpunkt d)

d) Podaj definicję parametru ‘’epsilon’’ i jego wartość domyślną. Wykonaj ponownie
obliczenia stosując wartości epsilon ze zbioru: 10^-1, 10^-2, 10^-3 i 10^-6. Porównaj
liczbę iteracji i wartości estymatorów poszczególnych parametrów.

Ze względu na to, że analityczne rozwiązanie równania $\nabla l(b) = 0$ (gdzie l(b) to funkcja likelihood względem parametrów modelu) nie istnieje, do obliczenia estymatorów współczynników modelu wykorzystywane są metody numeryczne. Parametr $\epsilon$ umożliwia kontrolę nad liczbą iteracji algorytmu. Zdefiniowany jest on jako $\frac{dev_{old} - dev}{|dev| + 0.1}$. Wartości występujące we wzorze to dewiancja aktualnego modelu oraz dewiancja modelu z poprzedniego kroku. Warto tutaj przypomnieć, że funkcja $l(b)$ jest funkcją wklęsłą co gwarantuje zbieżność algorytmu oraz $dev_{old} - dev \geq 0$. Wniosek jest taki, że zmniejszanie wartości $\epsilon$ spowoduje zwiększenie liczby iteracji ze względu na wymuszenie coraz dokładniejszej aproksymacji minimum globalnego. 

```{r epsilon}
epsilons <- c(1e-1, 1e-2, 1e-3, 1e-6)
model_e1 <- glm(success ~ numeracy + anxiety, data=data_df, family=binomial, epsilon=epsilons[1])
model_e2 <- glm(success ~ numeracy + anxiety, data=data_df, family=binomial, epsilon=epsilons[2])
model_e3 <- glm(success ~ numeracy + anxiety, data=data_df, family=binomial, epsilon=epsilons[3])
model_e4 <- glm(success ~ numeracy + anxiety, data=data_df, family=binomial, epsilon=epsilons[4])

models <- list(model_e1, model_e2, model_e3, model_e4)
epsilon_info_df <- as.data.frame(matrix(1:12, ncol=3))
colnames(epsilon_info_df) <- c("Iteration", "Epsilon", "Deviance")

for (i in 1:length(models)) {
  model <- models[[i]]
  epsilon_info_df[i, ] = c(model$iter, epsilons[i], model$dev)
}
epsilon_info_df
```


Zgodnie z oczekiwaniami zmniejszanie $\epsilon$ zwiększało liczbę iteracji oraz zmniejszało wartość statystyki deviance. Warto zauważyć, że różnice pomiędzy $\epsilon = 10^{-3}$ a $\epsilon = 10^{-6}$ są pomijalne. W praktyce dla dużych zbiorów danych zbyt duża liczba kroków algorytmu może w znaczący sposób wydłużyć czas uczenia. 

## Zadanie 2

Wygeneruj macierz X wymiaru n=400, p=3, której elementy są zmiennymi losowymi z rozkładu N(0, sigma^2=1/n). Załóżmy, że binarny wektor odpowiedzi jest wygenerowany zgodnie z modelem regresji logistycznej z wektorem beta=(3,3,3). Wyznacz macierz informacji
Fishera w punkcie beta i asymptotyczna macierz kowariancji estymatorów największej wiarogodności. Nastepnie 500 razy wygeneruj wektor odpowiedzi zgodnie z powyższym modelem. 

W związku z tym, że dane generowane są zgodnie z określonym schematem, model nie uwzględnia interceptu.
```{r assignment2_setup}
experiment_rep = 500

matrix_rnorm <- function(n, n_p) {
  X <- rnorm(n * n_p, sd=sqrt(1/n))
  X <- matrix(X, nrow=n)
}

cov_matrix <- function(n ,n_p) {
  mu <- rep(0, n_p)
  S <- matrix(0.3, nrow=n_p, ncol=n_p)
  diag(S) <- 1
  mvrnorm(n, mu, 1/n * S)
}

experiment <- function(n, n_p, X) {
  beta <- rep(3, n_p)
  logit <- X %*% beta
  p <- exp(logit) / (1 + exp(logit))
  
  S <- diag(as.vector(p*(1-p)))
  fisher_matrix <- t(X) %*% S %*% X
  cov_matrix <- solve(fisher_matrix)
  
  predictors <- c()
  for (i in 1:n_p) {
    predictors <- c(predictors, paste("beta", i, sep=''))
  }
  
  colnames(cov_matrix) <- predictors
  rownames(cov_matrix) <- predictors

  collected_features <- c(predictors, "resid_dev")
  collected_features_n <- length(collected_features)
    
  estimates_df <- matrix(1:collected_features_n * experiment_rep, nrow=experiment_rep, ncol=collected_features_n)
  estimates_df <- as.data.frame(estimates_df)
  colnames(estimates_df) <- collected_features
  
  for (i in 1:experiment_rep) {
    Y <- rbinom(n, 1, p)
    model <- glm(Y~X - 1, family=binomial)
    estimates_df[i, 1:n_p] <- model$coefficients
    estimates_df[i, n_p+1] <- model$deviance
  }
  
  list(estimates=estimates_df, cov_matrix=cov_matrix)
}  

show_estimates_histogram <- function(estimates_df, cov_matrix, n, n_hist=3) {
    estimates_df <- estimates_df %>% dplyr::select(c(1:n_hist, "resid_dev"))
  models_info_long <- estimates_df %>% 
                      dplyr::select(starts_with("beta")) %>% 
                      gather(key='coefficient', value='coefficient_value')

  density_arg <- seq(min(models_info_long["coefficient_value"]), 
                     max(models_info_long["coefficient_value"]), 
                     by=0.1)
  coefs_density <- data.frame(beta1=dnorm(density_arg, mean=3, sd=sqrt(cov_matrix[1,1])),
                              beta2=dnorm(density_arg, mean=3, sd=sqrt(cov_matrix[2,2])),
                              beta3=dnorm(density_arg, mean=3, sd=sqrt(cov_matrix[3,3])))
  coefs_density_long <- coefs_density %>% gather(key='coefficient', value='density')
  coefs_density_long["args"] = rep(density_arg, 3)


  histogram <- ggplot(models_info_long, aes(x=coefficient_value)) + 
             geom_histogram(aes(y=..density..), colour="black", fill="white") + 
             geom_density(col="red") +
             geom_line(data=coefs_density_long, aes(x=args, y=density), col="blue") +         
             facet_grid(. ~ coefficient) +
             ggtitle(paste("Regression coefficient estimates n =", n))
  histogram
}

show_residual_deviance <- function(estimates_df, n, p) {
  density_arg <- seq(min(n-p-10, min(estimates_df["resid_dev"])), 
                     max(estimates_df["resid_dev"]), 
                     by=0.1)
  density <- dchisq(density_arg, n-p)
  density_df <- data.frame(resid_dev=density_arg, density=density)
  
  estimates_df["density"] = dchisq(unlist(estimates_df["resid_dev"]), n-p)
  histogram <- ggplot(estimates_df, aes(x=resid_dev)) + 
               geom_histogram(aes(y=..density..), colour="black", fill="white") +
               geom_line(data=density_df, aes(x=resid_dev, y=density), col="blue") + 
               ggtitle("Residual deviance asymptotics")
  histogram
}

bias_estimation <- function(estimates_df) estimates_df %>% 
                                          dplyr::select(starts_with("beta")) %>% 
                                          mutate_all(function(x) {x-3}) %>% 
                                          colMeans()

variance_estimation <- function(estimates_df) estimates_df %>% 
                       dplyr::select(starts_with("beta")) %>% 
                       var()
```

### Podpunkt a)

Narysuj histogramy estymatorów beta1, beta2 i beta3 i ‘residual deviance’ i porównaj z ich rozkładami asymptotycznymi.

Zgodnie z twierdzeniem podanym na wykładzie wiem, że wektor estymtorów w regresji logistycznej jest asymptotycznie normalny:
$$
\hat{\beta} \xrightarrow{D} N(\beta, (X^TS(\beta)X)^{-1})
$$
przy czym $S(\beta)$ to macierz diagonalna mająca na przekątnej wartości postaci $p_i(1-p_i)$, $p_i = P(Y=1|X_i)$. Ze względu na schemat przeprowadzonego eksperymentu spodziewam się, że poszczególne współczynniki regresji otrzymane w kolejnych powtórzeniach powinny układać się zgodnie z rozkładem $N(3, 1)$. 

```{r histograms_coefficients_1}
estimates_res_400 <- experiment(400, 3, matrix_rnorm(400, 3))
estimates_df_400 <- estimates_res_400$estimates
cov_matrix_400 <- estimates_res_400$cov_matrix
histogram_400 <- show_estimates_histogram(estimates_df_400, cov_matrix_400, 400)
histogram_400
```

Niebieska linia na powyższym wykresie przedstawia gęstość rozkładu $N(3, 1)$. Można zaobserwować, że przybliżona linia gęstości rozkładu (kolor czerwony) reprezentująca ciągłą wersje histogramu odbiega w niewielkim stopniu od rozkładu asymptotycznego. 

Deviance ma asymptotyczny rozkład postaci: $ResidualDeviance \sim \chi^2_{n-p}$. Na wykresie można zaobserować, że wygenerowane wartości residual deviance znacznie różnią się od rozkładu asymptotycznego z czego mogę wnioskować o tym, że model nie był w stanie dopasować się do danych. 
```{r resid_deviance_1}
show_residual_deviance(estimates_df_400, 400, 3) 
```

Warto zastanowić się nieco bardziej nad tym problemem. Z histogramów wynika, że model jest w stanie określić poprawne wartości współczynników regresji, jednak współczynniki te mają relatywnie małą istotność. Poniżej zamieszczone zostało podsumowanie dla modelu dopasowanego w taki sposób w jaki dopasowywane są modele w pętli wykonywanej 500 razy. Można zaobserwować, że istotność poszczególnych predyktorów jest niska oraz istnieje niewielka różnica pomiędzy null deviance i residual deviance. 
```{r deviance_analysis}
X <- matrix_rnorm(400, 3)
beta <- rep(3, 3)
logit <- X %*% beta
p <- exp(logit) / (1 + exp(logit))
  
Y <- rbinom(400, 1, p)
model <- glm(Y~X - 1, family=binomial)
summary(model)
```

### Podpunkt b)

b) Wyestymuj obciążenie estymatorów beta1, beta2 i beta3.

Obiążenie estymatorów obliczone zostało jako średnia różnica pomiędzy $\beta = 3$ a estymatorem $\hat{\beta}$. Jako, że $\hat{\beta}$ jest estymatorem nieobciążonym oczekuje się, że wartość ta będzie malała wraz ze wzrostem liczby obserwacji (n).

```{r bias_estimation_1}
estimated_bias_400 <- bias_estimation(estimates_df_400)
estimated_bias_400
```

### Podpunkt c)

c) Wyestymuj macierz kowariancji wektora estymatorów (beta1, beta2, beta3) i porównaj z
asymptotyczną macierzą kowariancji.

Wyestymowana macierz kowariancji:
```{r variance_estimated_1}
est_var_400 <-variance_estimation(estimates_df_400)
est_var_400
```

Prawdziwa macierz kowariancji:
```{r true_variance_1}
true_var_400 <- estimates_res_400$cov_matrix
true_var_400
```

Wartości wariancji estymatorów (wartości na diagonali) są zbliżone do wartości prawdziwych, chociaż wyestymowana wariancja $\hat{\beta_i}$ jest systematycznie większa niż wariancja asymptotyczna.


## Zadanie 3

### Podpunkt a)

Zmniejszenie liczby obserwacji na podstawie których wyestymowane są współczynniki regresji logistycznej powoduje zwiększenie błędu estymacji współczynników $\beta$. Sytuacja ta jest w pewnym stopniu obserwowalna na poniższym zestawieniu histogamów, jednak zostanie uwypuklona w kolejnych podpunktach.

```{r histograms_coefficients_2}
estimates_res_100 <- experiment(100, 3, matrix_rnorm(100, 3))
estimates_df_100 <- estimates_res_100$estimates
cov_matrix_100 <- estimates_res_100$cov_matrix
histogram_100 <- show_estimates_histogram(estimates_df_100, cov_matrix_100, 100)

grid.arrange(histogram_100, histogram_400, nrow=2)
```

Wydaje się, że w tym scenariuszu deviance ma rozkład bardziej zbliżony do asymptotycznego niż dla n=100. Wynika to z tego, że dla słabych predyktorów
zwiekszanie ich liczby nie poprawia w znaczący sposób predykcji, zwiększa natomiast poziom szumu. Ogólna różnica deviance a null deviance jest większa dla n=400.
```{r resid_deviance_2}
show_residual_deviance(estimates_df_100, 100, 3) 
```

### Podpunkt b)

Warto zauważyć, że bias obliczony na podstawie zbioru treningowego rozmiaru n=100 jest większy niż bias dla zbioru treningowego rozmiaru n=400.
```{r bias_estimation_2}
estimated_bias_100 <- bias_estimation(estimates_df_100)
bias_summary_1 <- dplyr::bind_rows(estimated_bias_400, estimated_bias_100) %>% as.data.frame()
rownames(bias_summary_1) = c("n=400", "n=100")
bias_summary_1
```

### Podpunkt c)

Wyestymowana macierz kowariancji:
```{r variance_estimated_2}
est_var_100 <- variance_estimation(estimates_df_100)
est_var_100
```

Prawdziwa macierz kowariancji:
```{r true_variance_2}
true_var_100 <- estimates_res_100$cov_matrix
true_var_100
```

## Zadanie 4

W przeciwieństwie do poprzedniego zadania, zbiór treningowy został wygenerowany w taki sposób, że istnieje korelacja pomiędzy poszczególnymi predyktorami. Zjawisko to znane jest jako multicollinearity i stanowi efekt niepożądany. Korelacja pomiędzy predyktorami często powoduje problemy ze znalezieniem właściwych parametrów regresji. W szczególności można spodziewać się większej wariancji estymatorów.

### Wyniki dla n=400

#### Podpunkt a1)

```{r histograms_coefficients_3}
estimates_res_400 <- experiment(400, 3, cov_matrix(400, 3))
estimates_df_400 <- estimates_res_400$estimates
cov_matrix_400 <- estimates_res_400$cov_matrix
histogram_400 <- show_estimates_histogram(estimates_df_400, cov_matrix_400, 400)
histogram_400
```

```{r resid_deviance_3}
show_residual_deviance(estimates_df_400, 100, 3) 
```

#### Podpunkt b1)

```{r bias_estimation_3}
estimated_bias_400_cov <- bias_estimation(estimates_df_400)
estimated_bias_400_cov
```

#### Podpunkt c1)

```{r variance_estimated_3}
est_var_400_cov <- variance_estimation(estimates_df_400)
est_var_400_cov
```

```{r true_variance_3}
true_var_400_cov <- estimates_res_400$cov_matrix
true_var_400_cov
```

### Wyniki dla n=100

#### Podpunkt a2)

```{r histograms_coefficients_4}
estimates_res_100 <- experiment(100, 3, cov_matrix(100, 3))
estimates_df_100 <- estimates_res_100$estimates
cov_matrix_100 <- estimates_res_100$cov_matrix
histogram_100 <- show_estimates_histogram(estimates_df_100, cov_matrix_100, 100)

grid.arrange(histogram_100, histogram_400, nrow=2)
```

#### Podpunkt b2)

```{r bias_estimation_4}
estimated_bias_100_cov <- bias_estimation(estimates_df_100)
bias_summary_2 <- dplyr::bind_rows(estimated_bias_400_cov, estimated_bias_100_cov) %>% as.data.frame()
rownames(bias_summary_2) = c("n=400", "n=100")
bias_summary_2
```

```{r variance_estimated_4}
est_var_100_cov <- variance_estimation(estimates_df_100)
est_var_100_cov
```

#### Podpunkt c2)

```{r true_variance_4}
true_var_100_cov <- estimates_res_100$cov_matrix
true_var_100_cov
```

## Podsumownie dla p=3

Wydaje się, że w przypadku eksperymentu zawierającego dane skorelowane, otrzymany bias jest większy.
```{r bias_comparison}
bias_summary <- dplyr::bind_rows(estimated_bias_400, estimated_bias_100, estimated_bias_400_cov, estimated_bias_100_cov) %>% as.data.frame()
rownames(bias_summary) <- c("n=400", "n=100", "n=400 corr", "n=100 corr")
bias_summary
```

Zaproponowane porównanie wyestymowanej wariancji polega na odjęciu wariancji wyestymowanej oraz prawdziwej i wzięciu modułu z tak otrzymanej wartości. W wyniku tej procedury otrzymam 3 wartości mówiące o biasie estymatora wariancji. Otrzymane wartości nie wskazują na żadną oczywistą zależność pomiędzy estymatorami. Jedyną wartością, która odstaje od reszty to bias związany ze zbiorem treningowym rozmiaru n=100 i skorelowanymi predyktorami. W tym przypadku ogólny błąd był największy.
```{r estimates_comparison}
variance_bias <- function(true_var, est_var) {abs(diag(true_var - est_var))}

variance_bias_df <- data.frame(`n=400`=variance_bias(true_var_400, est_var_400),
                               `n=100`=variance_bias(true_var_100, est_var_100),
                               `n=400 corr`=variance_bias(true_var_400_cov, est_var_400_cov),
                               `n=100 corr`=variance_bias(true_var_100_cov, est_var_100_cov))
rowSums(t(variance_bias_df))
```


## Zadanie 5

Aby uniknać przedstawiania wyników dla wszystkich 20 estymatorów, ogranicze się do $\beta_1$, $\beta_2$ oraz $\beta_3$ (tam gdzie jest to konieczne).

### Wyniki dla n=400

#### Podpunkt a)


```{r histograms_coefficients_5}
estimates_res_400 <- experiment(400, 20, matrix_rnorm(400, 20))
estimates_df_400 <- estimates_res_400$estimates

cov_matrix_400 <- estimates_res_400$cov_matrix
histogram_400 <- show_estimates_histogram(estimates_df_400, cov_matrix_400, 400)
histogram_400
```

```{r resid_deviance_5}
show_residual_deviance(estimates_df_400, 400, 20) 
```

Podobnie jak w przypadku gdy liczba predyktorów wynosiła 3, niewiele spośród predyktorów zostało uznanych za istotne. Dodatkowo w obu przypadkach ponowne przeprowadzenie eksperymentu przypisuje istotność w inny sposób.
```{r deviance_analysis_5}
X <- matrix_rnorm(400, 20)
beta <- rep(3, 20)
logit <- X %*% beta
p <- exp(logit) / (1 + exp(logit))
  
Y <- rbinom(400, 1, p)
model <- glm(Y~X - 1, family=binomial)
summary(model)
```

#### Podpunkt b)

b) Obciążenie estymatorów

```{r bias_estimation_5}
estimated_bias_400 <- bias_estimation(estimates_df_400)
estimated_bias_400[1:3]
```

#### Podpunkt c)

c) Wyestymuj macierz kowariancji wektora estymatorów (beta1, beta2, beta3) i porównaj z
asymptotyczną macierzą kowariancji.

Wyestymowana macierz kowariancji:
```{r variance_estimated_5}
est_var_400 <-variance_estimation(estimates_df_400)
est_var_400[1:3, 1:3]
```

Prawdziwa macierz kowariancji:
```{r true_variance_5}
true_var_400 <- estimates_res_400$cov_matrix
true_var_400[1:3, 1:3]
```

Wartości wariancji estymatorów (wartości na diagonali) są zbliżone, chociaż wyestymowana wariancja $\hat{\beta_i}$ jest systematycznie większa niż wariancja asymptotyczna.


### Wyniki dla n=100

#### Podpunkt a)

Dla n=100 widać znaczną różnice pomiędzy wartościami wyestymowanymi a asymptotycznym rozkładem.

```{r histograms_coefficients_6}
estimates_res_100 <- experiment(100, 20, matrix_rnorm(100, 20))
estimates_df_100 <- estimates_res_100$estimates
cov_matrix_100 <- estimates_res_100$cov_matrix
histogram_100 <- show_estimates_histogram(estimates_df_100, cov_matrix_100, 100)

grid.arrange(histogram_100, histogram_400, nrow=2)
```

```{r resid_deviance_6}
show_residual_deviance(estimates_df_100, 100, 20) 
```

#### Podpunkt b)

```{r bias_estimation_6}
estimated_bias_100 <- bias_estimation(estimates_df_100)
bias_summary_1 <- dplyr::bind_rows(estimated_bias_400[1:3], estimated_bias_100[1:3]) %>% as.data.frame()
rownames(bias_summary_1) = c("n=400", "n=100")
bias_summary_1
```

#### Podpunkt c)

Wyestymowana macierz kowariancji:
```{r variance_estimated_6}
est_var_100 <- variance_estimation(estimates_df_100)
est_var_100[1:3,1:3]
```

Prawdziwa macierz kowariancji:
```{r true_variance_6}
true_var_100 <- estimates_res_100$cov_matrix
true_var_100[1:3,1:3]
```

## Przypadek ze skorelowanymi predyktorami

### Wyniki dla n=400

#### Podpunkt a)

```{r histograms_coefficients_7}
estimates_res_400 <- experiment(400, 20, cov_matrix(400, 20))
estimates_df_400 <- estimates_res_400$estimates
cov_matrix_400 <- estimates_res_400$cov_matrix
histogram_400 <- show_estimates_histogram(estimates_df_400, cov_matrix_400, 400)
histogram_400
```

```{r resid_deviance_7}
show_residual_deviance(estimates_df_400, 100, 3) 
```

#### Podpunkt b)

```{r bias_estimation_7}
estimated_bias_400_cov <- bias_estimation(estimates_df_400)
estimated_bias_400_cov[1:3]
```

#### Podpunkt c1)

```{r variance_estimated_7}
est_var_400_cov <- variance_estimation(estimates_df_400)
est_var_400_cov[1:3]
```

```{r true_variance_7}
true_var_400_cov <- estimates_res_400$cov_matrix
true_var_400_cov[1:3, 1:3]
```

### Wyniki dla n=100

#### Podpunkt a)

W scenariuszu dla zbioru testowego rozmiaru n=20 przy skorelowanych predyktorach algorytm estymacji współczynników regresji logistycznej nie zbiegł do optimum. 

```{r histograms_coefficients_8, warning=FALSE, include=FALSE}
estimates_res_100 <- experiment(100, 20, cov_matrix(100, 20))
estimates_df_100 <- estimates_res_100$estimates
cov_matrix_100 <- estimates_res_100$cov_matrix
```

#### Podpunkt b)

```{r bias_estimation_8}
estimated_bias_100_cov <- bias_estimation(estimates_df_100)
bias_summary_2 <- dplyr::bind_rows(estimated_bias_400_cov[1:3], estimated_bias_100_cov[1:3]) %>% as.data.frame()
rownames(bias_summary_2) = c("n=400", "n=100")
bias_summary_2
```

```{r variance_estimated_8}
est_var_100_cov <- variance_estimation(estimates_df_100)
est_var_100_cov[1:3]
```

#### Podpunkt c2)

```{r true_variance_8}
true_var_100_cov <- estimates_res_100$cov_matrix
true_var_100_cov[1:3]
```

## Podsumownie dla p=20

Podobnie do przypadku gdzie p=3, wydaje się, że w przypadku eksperymentu zawierającego dane skorelowane, otrzymany bias jest większy. W obu przypadkach wydaje się, że największy wpływ na popełniany błąd ma rozmiar zbioru treningowego.
```{r bias_comparison_1}
bias_summary <- dplyr::bind_rows(estimated_bias_400, estimated_bias_100, estimated_bias_400_cov, estimated_bias_100_cov) %>% as.data.frame()
rownames(bias_summary) <- c("n=400", "n=100", "n=400 corr", "n=100 corr")
t(bias_summary[, 1:3])
```

Analogicznie do biasu estymatorów, estymator wariancji poszczególnych współczynników jest większy dla danych skorelowanych. W tym przypadku wydaje się jednak, że kluczową rolę odgrywa romiar zbioru treningowego, a nie korelacja predyktorów.
```{r estimates_comparison_1}
variance_bias_df <- data.frame(`n=400`=variance_bias(true_var_400, est_var_400),
                               `n=100`=variance_bias(true_var_100, est_var_100),
                               `n=400 corr`=variance_bias(true_var_400_cov, est_var_400_cov),
                               `n=100 corr`=variance_bias(true_var_100_cov, est_var_100_cov))
variance_bias_df[1:3,]
```




